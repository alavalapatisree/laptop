1))
cd ~ - This command changes the current directory to your home directory. The tilde (~) is a shorthand notation for the home directory of the current user.
cd /path/to/directory
cd ..
cd -  -> This command switches back to the previous directory you were in before the last cd command. 
cd ~username
cd / -This command changes the current directory to the root directory, which is the top-level directory in the file system hierarchy.

2))
ls
ls -l
ls -la   -> Lists all files and directories, including hidden ones (those starting with a dot). In long format.
ls -lh   -> Lists in long format with human-readable file sizes (e.g., "2.5M" instead of bytes).
ls -R    -> Lists files and directories recursively, showing the contents of subdirectories as well.
ls -lR   -> Lists files and directories recursively in long format.
ls -lRh  
ls -lt   -> Lists files and directories, sorting by modification time, with the most recently modified files first.
ls -lS   -> Lists files and directories in long format, sorting by file size in descending order (largest files first).

3))
pwd

4))
cat 1.txt
cat 1.txt 2.txt
cat -n 1.txt
cat -E 1.txt   -> Displays the contents of "1.txt" with a dollar sign ($) at the end of each line to indicate the end of lines.
cat -T 1.txt   -> Displays the contents of "1.txt" with tabs (^I) represented as ^I in the output.
cat 1.txt 2.txt > a.txt

5))
touch a.txt
touch b.txt c.txt d.txt
touch <existing_file name> (to change timestamp)
touch -t YYYYMMDDHHMM.SS <file_name>

6))
cp file.txt home/thor/aaa
cp -r home/thor/aaa home/thor/bbb
cp -a 1.txt aaa/ (to preserve timestamps, permissions, file content)
cp -i 1.txt aaa/ (interactive session to get conformation for overwrite)
cp -v k.txt 8030/ (show us the details of copying files)
cp -f 1.txt /aaa   (forceful)
cp a.txt b.txt c.txt aaa/

7))
mv <source> <destination>
mv 1.txt rupa/
mv 1.txt 2.txt
mv 1.txt rupa/two.txt
mv 8030/ 1631/
mv -i sree.txt 1631/
mv -f sree.txt 1631/
mv -v 1.txt 1631/

8))
rm file.txt
rm a.txt b.txt
rm -r 8030/
rm -i a.txt
rm -f b.txt
rm -v c.txt

9))
mkdir dir1
mkdir dir1 dir2 dir3
mkdir -p dir5/dir6
mkdir -m 755 dir7

10))
rmdir dir1
rmdir dir2 dir3 dir4
rmdir -p dir5/dir6 (path to thr empty folder) (enter path will be deleted)

11)
cut -c 1-4 2.txt   			-> Cuts and displays characters 1 to 4 from each line of the "2.txt" file.
cut -f 1,3,4 a.txt  			-> Cuts and displays fields 1, 3, and 4 from each line of the "a.txt" file. Fields are separated by tabs by default. If you have a different delimiter, you 					   can specify it using the -d option.
cut -d'@' -f1,3 a.txt  			-> Cuts and displays fields 1 and 3 from each line of the "a.txt" file, using the "@" character as the field delimiter.
echo 'this is jhon' | cut -d'n' -f1	-> Cuts and displays the first field (before the "n" character) from the input text "this is jhon."

12))
gzip file.txt  (otput - file.txt.gz)
gzip file.txt one.gz
gzip file1.txt file2.txt file3.txt (compressing multiple files -- output -- file1.txt.gz file2.txt.gz file3.txt.gz)

13))
gunzip one.gz
gzip -d one.gz
gunzip file1.txt.gz file2.txt.gz file3.txt.gz
gzip -d file1.txt.gz file2.txt.gz file3.txt.gz
gunzip -c example.txt.gz  (to see the content without decompressing the file)

14))
tar czf rupa.tar.gz file1.txt file2.txt file3.txt
tar xzf rupa.tar.gz
tar -czf compressed_folder.tar.gz /path/to/folder

15))
find <directory> <options> <pattern type>
find aaa/ -name 1.txt
find aaa/ -iname rupa.txt
find aaa/ -name "*.txt"
find aaa/ -type f
find aaa/ -type d
find aaa/ -type f -size +1M
find aaa/ -type f -size -100k
find aaa/ -user <username>
find aaa/ -perm u=rw (exact read and write)
find aaa/ -perm /u=rw (atleast read and write)
find aaa/ -type f -exec echo {} \;
find aaa/ -type f -exec rm {} \;
find aaa/ -maxdepth 1 -type f
find aaa/ -maxdepth 2 -type f
find aaa/ -mtime -9 (modified within last 9 days)
find aaa/ -mtime 9 (modified exactly 9 days ago)

16))
grep "pattern" file.txt (Search for a specific pattern in a file:)
grep "pattern" file1.txt file2.txt (Search for a pattern in multiple files:)
grep "pattern" /path/to/directory/* ( Search for a pattern in all files in a directory:)
grep -i "pattern" file.txt (Case-insensitive search:)
grep -n "pattern" file.txt (Display line numbers of matching lines:)
grep -o "pattern" file.txt (Display only the matching part of the line:)
grep -r "pattern" /path/to/directory/ (Search for a pattern in all subdirectories:)
grep -v "pattern" file.txt (Invert the match (show lines that do not match):)
grep -c "pattern" file.txt (Count the number of matching lines:)
grep "pattern" *.txt (Search for a pattern in a specific file type (e.g., all .txt files):)
grep -I "pattern" * (Search for a pattern, ignoring binary files:)

17))
head example.txt
head -n 20 data.csv
head -c 50 binary.dat (o display the first 50 bytes of a binary file named "binary.dat":)
head -v file1.txt file2.txt  ---> displays 10 lines of each file

18))
tail example.log
tail -n 20 data.txt
tail -c 50 binary.dat
tail -f access.log    -> -f: The -f option, also known as "follow" or "continuous" mode, makes tail monitor the file for updates. As new lines are added to the file, they are automatically 				 displayed in the terminal.
tail -v file1.txt file2.txt

19))
sort file.txt   -> Sorts the lines in the "file.txt" in ascending order (alphabetically).
100
20
3
50
9


100
20
3
50
9

sort -r numbers.txt   -> orts the lines in the "numbers.txt" file in reverse order (descending order).
sort -n scores.txt    -> Sorts the lines in the "scores.txt" file in ascending numeric order (numerically).
100
20
3
50
9

3
9
20
50
100

sort -rf file.txt (case insensitive)   -> orts the lines in the "file.txt" file in ascending order (alphabetically), but in a case-insensitive manner.
sort -u sorted.txt (removing duplicate and sorting)  -> Sorts the lines in the "sorted.txt" file in ascending order (alphabetically) and removes duplicate lines.

20))
uniq sorted.txt    ->  Displays only the unique lines from the "sorted.txt" file, removing duplicate lines.
uniq -d sorted.txt -> Displays only the duplicate lines from the "sorted.txt" file, omitting the unique lines.
uniq -c sorted.txt (To display only the unique lines and their counts from a sorted file) -> It shows how many times each unique line appears in the file.

21))
wc document.txt    -> Counts the number of lines, words, and characters in the "document.txt" file and displays the result.
wc -l file.txt	   -> Counts only the number of lines in the "file.txt" file and displays the result.
wc -w poem.txt	   -> Counts only the number of words in the "poem.txt" file and displays the result.
wc -m poem.txt	   -> Counts the number of characters (bytes) in the "poem.txt" file and displays the result.
wc -c binary.dat   -> Counts the number of bytes (characters) in the "binary.dat" file. This is typically used for binary files.
cat data.txt | wc  -> Uses a pipe to first concatenate the contents of "data.txt" using cat and then counts the lines, words, and characters in the concatenated output using wc.

22)
diff -u file1.txt file2.txt
diff -r dir1 dir2
diff -q config_old.txt config_new.txt  -> The diff command with the -q option is used to compare two text files and report whether they are different. If the files are identical, it will produce 					  no output. 
diff -y script1.sh script2.sh 	       -> The diff command with the -y option is used to compare two text files side by side, displaying the differences between them in a side-by-side format. 

23)
whatis

24))
chmod u+rw,go+r example.txt
chmod ug+x myscript.sh
chmod 711 myscript.sh
chmod go-w data
chmod -R u+rw project           ->Recursively grants read and write permissions to the owner for all files and directories under the "project" directory. This operation is applied recursively to 				  all subdirectories and files within "project."

25))
chown new_owner: file.txt 			-> Change the owner of a file or directory
chown new_owner:new_group file.txt 		-> Change the owner and group of a file or directory
chown -R new_owner:new_group directory/ 	-> Change the owner and group recursively for a directory and its contents
chown 1001:1002 file.txt 			-> Change the owner of a file or directory using the user's numerical UID and GID
chown :new_group file.txt 			-> Preserve the owner of a file when only changing the group
chown --reference=reference_file target_file 	-> Change the owner and group of a file using a reference file
sudo chown $(whoami) file.txt  			-> The command sudo chown $(whoami) file.txt is used to change the ownership of the "file.txt" to the currently logged-in user. 

26))
chgrp new_group file.txt 			-> Change the group ownership of a file or directory
chgrp -R new_group directory/ 			-> Change the group ownership recursively for a directory and its contents
chgrp :new_group file.txt 			-> Preserve the owner when changing the group (use a colon : to specify only the group)
chgrp --reference=reference_file target_file 	-> Change the group ownership of a file using a reference file
sudo chgrp user_group file.txt 			-> Change the group ownership to the group of another user (useful for administrators with sudo privileges)

27))
ps 			-> ist all processes running in the current terminal session
ps -u <username> 	-> ps -u command is used to list the processes running on a Unix or Unix-like operating system for a specific user.
ps -l 			-> The ps -l command provides a long format list of all processes running on the system. 
ps aux 			-> Provides an extensive list of information about all processes, including user, PID, CPU usage, memory usage, terminal, command, and more. It shows processes from all 			   users.
ps -p <ID>  		-> List processes with a specific process ID


28))
top - top is an interactive and dynamic command-line utility for monitoring system resource usage and viewing information about running processes in real-time on Linux systems.
Press "P" to sort the list of processes by CPU usage.
Press "M" to sort the list of processes by memory usage.
Press "k" to kill a selected process.
Press "u" to filter processes by a specific user.
Press "f" to customize the fields and columns displayed.
Press "R" to renice (change process priority) a selected process.
Press "q" to quit top.

29))
awk is a versatile and powerful text processing and pattern scanning language and utility in Unix-like operating systems.

awk '{print $1, $3}' 1.txt 				-> Print specific fields of a file
awk '$3 > 50 {print $1, $3}' 1.txt 			-> Filter lines based on a condition
awk '{sum += $2} END {print "sum :", sum} 1.txt 	-> Calculate and print the sum of a column
awk '/Bob/ {print}' 1.txt 				-> Search for a specific pattern and print matching lines
awk 'tolower($0) ~ /bob/ {print}' 1.txt 		-> To perform a case-insensitive search with awk, you can use the tolower function to convert the text to lowercase before comparing it with 							   the pattern.
awk 'toupper($0) ~ /bob/ {print}' 1.txt			-> To perform a case-insensitive search with awk, you can use the tolower function to convert the text to uppercase before comparing it with 							   the pattern.


30))
sed 's/old/new/g' 1.txt 				-> Replace all occurrences of "old" with "new" in a file and print the result to the standard output
sed 's/old//g' 1.txt 					-> just to remove all iccurances
sed -i 's/old/new/g' 1.txt 				-> modify and save in 1.txt
sed -n '5,10p' 1.txt 					-> Print lines 5 to 10 of a file
sed '/pattern/d' 1.txt 					-> Delete lines containing a specific pattern
sed '/^[[:space:]]*$/d' input.txt > output.txt 		-> to delete spaces between lines